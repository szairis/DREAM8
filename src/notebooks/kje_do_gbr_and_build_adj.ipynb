{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import math\n",
      "from scipy.misc import comb\n",
      "from sklearn.ensemble import GradientBoostingRegressor\n",
      "from sklearn import linear_model\n",
      "from sklearn import metrics\n",
      "from sklearn import cross_validation\n",
      "from sklearn import preprocessing\n",
      "import models\n",
      "import utilities\n",
      "reload(utilities)\n",
      "\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## INSILICO\n",
      "\n",
      "# load data\n",
      "project_path = '../'\n",
      "data_path = os.path.join(project_path, 'dat')\n",
      "insilico_data = pd.read_csv(os.path.join(data_path, 'insilico', 'CSV', 'insilico.csv'), header=0)\n",
      "inhibs = set(insilico_data['Inhibitor'])\n",
      "stims = set(insilico_data['Stimulus'])\n",
      "\n",
      "node_list = ['AB{0:02d}'.format(i) for i in range(1, 21)]\n",
      "inhib_targets = {'INH1' : 'AB12', 'INH2' : 'AB05', 'INH3' : 'AB08'}\n",
      "#INH_targets = ['_'.join(['Inhib', node]) for node in node_list]\n",
      "\n",
      "# wrangle data\n",
      "regGBR= {}\n",
      "scalar = {}\n",
      "td = utilities.prepare_markov_data(utilities.introduce_inhibs(insilico_data, inhib_targets=inhib_targets, perfect=True), 'level', group_stimuli=True)\n",
      "X, Y = td['all_stimuli']\n",
      "scalar['all_stimuli'] = preprocessing.StandardScaler()\n",
      "scalar['all_stimuli'].fit_transform(X)\n",
      "X.ix[X.ix[:,'Inhib_INH1']>0,'Inhib_INH1'] = 1\n",
      "X.ix[X.ix[:,'Inhib_INH2']>0,'Inhib_INH2'] = 1\n",
      "X.ix[X.ix[:,'Inhib_INH3']>0,'Inhib_INH3'] = 1\n",
      "X.ix[X.ix[:,'Inhib_INH1']<0,'Inhib_INH1'] = 0\n",
      "X.ix[X.ix[:,'Inhib_INH2']<0,'Inhib_INH2'] = 0\n",
      "X.ix[X.ix[:,'Inhib_INH3']<0,'Inhib_INH3'] = 0\n",
      "\n",
      "# Step 2 : Fit\n",
      "n_estimators = 100\n",
      "max_depth = 3\n",
      "\n",
      "regGBR['all_stimuli'] = network_gbr(X, Y, n_estimators=n_estimators, max_depth=max_depth)\n",
      "#plot_regGBR(X, regGBR, test_score, n_estimators=n_estimators)\n",
      "\n",
      "# Step 3 : build and write adjacency matrix\n",
      "adj = build_adj_matrix(regGBR, node_list, ['all_stimuli'])\n",
      "utilities.write_SIF_EDA(adj['all_stimuli'], '../subchallenge1/submission5/sakev-Network-Insilico/sakev-Network-Insilico')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bt20 = pd.read_csv('../dat/experimental/CSV/BT20_main.csv')\n",
      "bt549 = pd.read_csv('../dat/experimental/CSV/BT549_main.csv')\n",
      "mcf7 = pd.read_csv('../dat/experimental/CSV/MCF7_main.csv')\n",
      "uacc812 = pd.read_csv('../dat/experimental/CSV/UACC812_main.csv')\n",
      "\n",
      "td_bt20 = utilities.prepare_markov_data(bt20, 'level', False)\n",
      "td_bt549 = utilities.prepare_markov_data(bt549, 'level', False)\n",
      "td_mcf7 = utilities.prepare_markov_data(mcf7, 'level', False)\n",
      "td_uacc812 = utilities.prepare_markov_data(uacc812, 'level', False)\n",
      "\n",
      "oldprior = pd.read_csv('../dat/experimental/experimental_prior.csv', index_col=0, header=0)\n",
      "A_true_bt20 = oldprior\n",
      "A_true_bt549 = A_true_bt20.ix[td_bt549['EGF'][0].columns, td_bt549['EGF'][0].columns]\n",
      "A_true_mcf7 = A_true_bt20.ix[td_mcf7['EGF'][0].columns, td_mcf7['EGF'][0].columns]\n",
      "A_true_uacc812 = A_true_bt20.ix[td_uacc812['EGF'][0].columns, td_uacc812['EGF'][0].columns]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## EXPERIMENTAL\n",
      "\n",
      "# load data\n",
      "project_path = '../'\n",
      "data_path = os.path.join(project_path, 'dat')\n",
      "data = pd.read_csv(os.path.join(data_path, 'experimental', 'CSV', 'UACC812_main.csv'), header=0)\n",
      "inhibs = set(data['Inhibitor'])\n",
      "stims = set(data['Stimulus'])\n",
      "\n",
      "node_list = data.columns[4:]\n",
      "inhib_targets = {'GSK690693' : ['AKT_pT308','AKT_pS473'],\n",
      "                 'GSK690693_GSK1120212' : ['AKT_pT308','AKT_pS473','MEK1_pS217_S221']}\n",
      "\n",
      "# wrangle data\n",
      "regGBR= {}\n",
      "scalar = {}\n",
      "td = utilities.prepare_markov_data(utilities.introduce_inhibs(data, inhib_targets=inhib_targets, perfect=True), 'level', group_stimuli=False)\n",
      "for stim in td:\n",
      "    X, Y = td[stim]\n",
      "    scalar[stim] = preprocessing.StandardScaler()\n",
      "    scalar[stim].fit_transform(X)\n",
      "    X.ix[X.ix[:,'Inhib_GSK690693']>0,'Inhib_GSK690693'] = 1\n",
      "    X.ix[X.ix[:,'Inhib_GSK690693_GSK1120212']>0,'Inhib_GSK690693_GSK1120212'] = 1\n",
      "    X.ix[X.ix[:,'Inhib_GSK690693']<0,'Inhib_GSK690693'] = 0\n",
      "    X.ix[X.ix[:,'Inhib_GSK690693_GSK1120212']<0,'Inhib_GSK690693_GSK1120212'] = 0\n",
      "    # Step 2 : Fit\n",
      "    n_estimators = 100\n",
      "    max_depth = 3\n",
      "    regGBR[stim] = network_gbr(X, Y, n_estimators=n_estimators, max_depth=max_depth)\n",
      "\n",
      "# Step 3 : build and write adjacency matrix\n",
      "adj = build_adj_matrix(regGBR, node_list, stims)\n",
      "for stim in adj:\n",
      "    path = '../subchallenge1/submission5/sakev-Network/sakev-UACC812-{0}-Network'.format(stim)\n",
      "    for row in A_true_uacc812.index:\n",
      "        for col in A_true_uacc812.columns:\n",
      "            if A_true_uacc812.ix[row,col] == 1:\n",
      "                tmp = adj[stim].ix[row,col] ** (0.5)\n",
      "                adj[stim].ix[row,col] = tmp\n",
      "            else:\n",
      "                tmp = adj[stim].ix[row,col] ** 2\n",
      "                adj[stim].ix[row,col] = tmp\n",
      "    utilities.write_SIF_EDA(adj[stim], path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for row in A_true_bt549.index:\n",
      "    for col in A_true_bt549.columns:\n",
      "        if A_true_bt549.ix[row,col] == 1:\n",
      "            print row,col\n",
      "            print adj['EGF'].ix[row,col] ** (0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AKT_pS473 AKT_pT308\n",
        "0.250990707652\n",
        "AKT_pS473 GSK3-alpha-beta_pS21_S9\n",
        "0.163766639607\n",
        "AKT_pS473 GSK3-alpha-beta_pS9\n",
        "0.260976578876\n",
        "AKT_pS473 p27_pT157\n",
        "0.133317338523\n",
        "AKT_pS473 p27_pT198\n",
        "0.180540950171\n",
        "AKT_pT308 AKT_pS473\n",
        "0.218436399533\n",
        "AKT_pT308 BAD_pS112\n",
        "0.071528948895\n",
        "AKT_pT308 GSK3-alpha-beta_pS21_S9\n",
        "0.0942271379198\n",
        "AKT_pT308 GSK3-alpha-beta_pS9\n",
        "0.186119721183\n",
        "AKT_pT308 p27_pT157\n",
        "0.0163366021562\n",
        "AKT_pT308 p27_pT198\n",
        "0.24250733115\n",
        "AKT_pT308 PRAS40_pT246\n",
        "0.00174726590842\n",
        "AMPK_pT172 ACC_pS79\n",
        "0.107055168194\n",
        "AMPK_pT172 mTOR_pS2448\n",
        "0.072509460577\n",
        "c-Met_pY1235 c-Raf_pS338\n",
        "0.113201651889\n",
        "c-Raf_pS338 MEK1_pS217_S221\n",
        "0.205183574269\n",
        "EGFR_pY1068 c-Raf_pS338\n",
        "0.0393153219528\n",
        "EGFR_pY1068 EGFR_pY1173\n",
        "0.276012435601\n",
        "EGFR_pY1068 HER2_pY1248\n",
        "0.188222813145\n",
        "EGFR_pY1068 JNK_pT183_pT185\n",
        "0.142036716453\n",
        "EGFR_pY1068 Src_pY416\n",
        "0.0753601330035\n",
        "EGFR_pY1068 Src_pY527\n",
        "0.0514103454332\n",
        "EGFR_pY1068 STAT3_pY705\n",
        "0.0933562044778\n",
        "EGFR_pY1173 c-Raf_pS338\n",
        "0.116683927037\n",
        "EGFR_pY1173 EGFR_pY1068\n",
        "0.05080951995\n",
        "EGFR_pY1173 HER2_pY1248\n",
        "0.16689379621\n",
        "EGFR_pY1173 JNK_pT183_pT185\n",
        "0.090204958848\n",
        "EGFR_pY1173 PKC-alpha_pS657\n",
        "0.0124415127603\n",
        "EGFR_pY1173 PKC-delta_pS664\n",
        "0.0505568838823\n",
        "EGFR_pY1173 PKC-pan-betaII_pS660\n",
        "0.130388101618\n",
        "EGFR_pY1173 Src_pY416\n",
        "0.116731056754\n",
        "EGFR_pY1173 Src_pY527\n",
        "0.033192550504\n",
        "HER2_pY1248 EGFR_pY1068\n",
        "0.0398421197796\n",
        "HER2_pY1248 EGFR_pY1173\n",
        "0.015482787598\n",
        "HER3_pY1298 AKT_pT308\n",
        "0.0852121634393\n",
        "JNK_pT183_pT185 PEA15_pS116\n",
        "0.0626876703103\n",
        "MAPK_pT202_Y204 p70S6K_pT389\n",
        "0.00615371977749\n",
        "MAPK_pT202_Y204 p90RSK_pT359_S363\n",
        "0.104593401758\n",
        "MEK1_pS217_S221 MAPK_pT202_Y204\n",
        "0.125052902829\n",
        "MEK1_pS217_S221 p38_pT180_Y182\n",
        "0.0632225861135\n",
        "mTOR_pS2448 4EBP1_pS65\n",
        "0.0254302975769\n",
        "mTOR_pS2448 4EBP1_pT37_pT46\n",
        "0.124466248232\n",
        "mTOR_pS2448 p70S6K_pT389\n",
        "0.254849135706\n",
        "mTOR_pS2448 p90RSK_pT359_S363\n",
        "0.101908735499\n",
        "mTOR_pS2448 Rictor_pT1135\n",
        "0.110949613185\n",
        "NDRG1_pT346 NF-kB-p65_pS536\n",
        "0.0746253851494\n",
        "p70S6K_pT389 Rictor_pT1135\n",
        "0.130119266247\n",
        "p70S6K_pT389 S6_pS235_S236\n",
        "0.217781460191\n",
        "p70S6K_pT389 S6_pS240_S244\n",
        "0.186054799402\n",
        "p90RSK_pT359_S363 Rictor_pT1135\n",
        "0.131405225709\n",
        "p90RSK_pT359_S363 S6_pS235_S236\n",
        "0.0260330146086\n",
        "p90RSK_pT359_S363 S6_pS240_S244\n",
        "0.0789730181392\n",
        "PDK1_pS241 AKT_pT308\n",
        "0.067918390494\n",
        "PKC-alpha_pS657 c-Raf_pS338\n",
        "0.0656655175152\n",
        "Rictor_pT1135 AKT_pS473\n",
        "0.080362428752\n",
        "Src_pY527 c-Raf_pS338\n",
        "0.167919800523\n",
        "Src_pY527 STAT3_pY705\n",
        "0.0940998275885\n",
        "STAT3_pY705 NF-kB-p65_pS536\n",
        "0.211114050131\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### FUNCTIONS\n",
      "\n",
      "def build_adj_matrix(regGBR, node_list, stims):   \n",
      "    num_nodes = len(node_list)\n",
      "    adj_dict = {}\n",
      "    for stim in stims:\n",
      "        adj = np.zeros((num_nodes, num_nodes), dtype='f')\n",
      "        for nidx, node in enumerate(node_list):\n",
      "            adj[:, nidx] = regGBR[stim][node].feature_importances_[:num_nodes]\n",
      "        adj_dict[stim] = pd.DataFrame(adj, index=node_list, columns=node_list)\n",
      "        \n",
      "    return adj_dict\n",
      "\n",
      "def network_gbr(X, Y, n_estimators=100, learning_rate=0.1, max_depth=5, verbose=False):\n",
      "\n",
      "    regGBR = {}\n",
      "\n",
      "    for target in Y.columns:\n",
      "        \n",
      "        if verbose:\n",
      "            print target\n",
      "        \n",
      "        # get target values\n",
      "        y = Y[target].values\n",
      "        \n",
      "        regGBR[target] = GradientBoostingRegressor(n_estimators=n_estimators,\n",
      "                                                        learning_rate=learning_rate,\n",
      "                                                        max_depth=max_depth,\n",
      "                                                        loss='ls')\n",
      "        regGBR[target].fit(X, y)\n",
      "        \n",
      "    return regGBR\n",
      "\n",
      "def plot_regGBR(X, regGBR, n_estimators=100):\n",
      "    for target in regGBR:\n",
      "\n",
      "        train_set_score = regGBR[target].train_score_\n",
      "    \n",
      "        #plot training deviance\n",
      "        fig = plt.figure(figsize=(16,18))\n",
      "        plt.subplot(1, 2, 1)\n",
      "        plt.title('{0} Deviance'.format(target))\n",
      "        \n",
      "        plt.plot(np.arange(n_estimators) + 1, train_set_score, label='Training Set Deviance')\n",
      "        plt.legend(loc='upper right')\n",
      "        plt.xlabel('Boosting Iterations')\n",
      "        plt.ylabel('Deviance')\n",
      "        \n",
      "        # Plot feature importants\n",
      "        \n",
      "        feature_scores = regGBR[target].feature_importances_\n",
      "        \n",
      "        # make importances relative to max importance\n",
      "    \n",
      "        sorted_idx = np.argsort(feature_scores)\n",
      "        pos = np.arange(sorted_idx.shape[0]) + .5\n",
      "        plt.subplot(1, 2, 2)\n",
      "        plt.barh(pos, feature_scores[sorted_idx], align='center')\n",
      "        plt.yticks(pos, X.columns[sorted_idx])\n",
      "        plt.xlabel('Relative Importance')\n",
      "        plt.title('{0} Variable Importance'.format(target))\n",
      "    \n",
      "        #fig.savefig(os.path.join(project_path, 'fig', 'gbr_model', '{0}_gbr_performance_take2.pdf'.format(target)), format='pdf')\n",
      "        #plt.close()\n",
      "\n",
      "def network_gbr_cv(X, Y, verbose=False, n_estimators=100, learning_rate=0.1, max_depth=5):\n",
      "    \n",
      "    n_folds = 5\n",
      "    kf = list(cross_validation.KFold(X.shape[0], n_folds=n_folds, shuffle=True))\n",
      "    \n",
      "    regGBR = {}\n",
      "    test_score = {}\n",
      "\n",
      "    for target in Y.columns:\n",
      "        \n",
      "        if verbose:\n",
      "            print target\n",
      "        \n",
      "        # get target values\n",
      "        y = Y[target].values\n",
      "        \n",
      "        regGBR[target] = []\n",
      "        test_score[target] = []\n",
      "        \n",
      "        for fold in range(n_folds):\n",
      "            if verbose:\n",
      "                print 'cv fold ', fold\n",
      "            X_train, y_train = X.ix[kf[fold][0],:], y[kf[fold][0]]\n",
      "            X_test, y_test = X.ix[kf[fold][1],:], y[kf[fold][1]]\n",
      "        \n",
      "            regGBR[target].append(GradientBoostingRegressor(n_estimators=n_estimators,\n",
      "                                                            learning_rate=learning_rate,\n",
      "                                                            max_depth=max_depth,\n",
      "                                                            loss='ls'))\n",
      "            regGBR[target][fold].fit(X_train, y_train)\n",
      "        \n",
      "            test_score[target].append(np.zeros((n_estimators,), dtype=np.float64))\n",
      "            \n",
      "            for i, y_pred in enumerate(regGBR[target][fold].staged_decision_function(X_test)):\n",
      "                test_score[target][fold][i] = regGBR[target][fold].loss_(y_test, y_pred)\n",
      "        \n",
      "        #mse = mean_squared_error(y_test, regGBR[target].predict(logB_test))\n",
      "        \n",
      "    return regGBR, test_score\n",
      "\n",
      "\n",
      "def plot_regGBR_cv(X, regGBR, test_score, n_estimators=100):\n",
      "    for target in regGBR:\n",
      "    \n",
      "        test_set_scores = np.zeros((n_folds, n_estimators))\n",
      "        train_set_scores = np.zeros((n_folds, n_estimators))\n",
      "        for i in range(n_folds):\n",
      "            test_set_scores[i,:] = test_score[target][i]\n",
      "            train_set_scores[i, :] = regGBR[target][i].train_score_\n",
      "        \n",
      "        mean_test_set_deviance = test_set_scores.mean(axis=0)\n",
      "        mean_train_set_deviance = train_set_scores.mean(axis=0)\n",
      "        std_test_set_deviance = test_set_scores.std(axis=0)\n",
      "        std_train_set_deviance = train_set_scores.std(axis=0)\n",
      "    \n",
      "        #plot training deviance\n",
      "        fig = plt.figure(figsize=(16,18))\n",
      "        plt.subplot(1, 2, 1)\n",
      "        plt.title('{0} Deviance'.format(target))\n",
      "        \n",
      "        plt.errorbar(np.arange(n_estimators) + 1, mean_train_set_deviance,\n",
      "                     yerr=std_train_set_deviance, fmt='b-', label='Training Set Deviance')\n",
      "        plt.errorbar(np.arange(n_estimators) + 1, mean_test_set_deviance,\n",
      "                     yerr=std_test_set_deviance, fmt='r-', label='Test Set Deviance')\n",
      "        plt.legend(loc='upper right')\n",
      "        plt.xlabel('Boosting Iterations')\n",
      "        plt.ylabel('Deviance')\n",
      "        \n",
      "        # Plot feature importants\n",
      "        \n",
      "        feature_scores = np.zeros((n_folds, len(regGBR[target][0].feature_importances_)))\n",
      "        for i in range(n_folds):\n",
      "            feature_importance = regGBR[target][i].feature_importances_\n",
      "            feature_scores[i, :] = 100.0 * (feature_importance / feature_importance.max())\n",
      "        mean_feature_importance = feature_scores.mean(axis=0)\n",
      "        std_feature_importance = feature_scores.std(axis=0)\n",
      "        \n",
      "        # make importances relative to max importance\n",
      "    \n",
      "        sorted_idx = np.argsort(mean_feature_importance)\n",
      "        pos = np.arange(sorted_idx.shape[0]) + .5\n",
      "        plt.subplot(1, 2, 2)\n",
      "        plt.barh(pos, mean_feature_importance[sorted_idx], align='center', xerr=std_feature_importance[sorted_idx])\n",
      "        plt.yticks(pos, X.columns[sorted_idx])\n",
      "        plt.xlabel('Relative Importance')\n",
      "        plt.title('{0} Variable Importance'.format(target))\n",
      "    \n",
      "        #fig.savefig(os.path.join(project_path, 'fig', 'gbr_model', '{0}_gbr_performance_take2.pdf'.format(target)), format='pdf')\n",
      "        #plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}